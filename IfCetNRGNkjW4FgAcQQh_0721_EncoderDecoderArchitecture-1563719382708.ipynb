{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0721_EncoderDecoderArchitecture.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "outputId": "03e15a7f-e461-45bc-cd04-f9228c406fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "outputId": "24b9a7a8-d16a-4480-a78e-1af28eec650b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "f8cceb21-881e-4bf4-aa32-e40795411d88"
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "outputId": "279948f9-59ec-477a-fd44-8ddf8c96f368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "PAWANA - पवाना\n",
            "CASTANEDA - कॅसटेनेडा\n",
            "MILTON - मिल्टन\n",
            "IRON - आयरन\n",
            "DHARTI - धरती\n",
            "UNIVERSITY - यूनिवर्सिटी\n",
            "THROGS - थ्रॉग्ज\n",
            "DUNIYA - दुनिया\n",
            "BANAHI - बनाही\n",
            "UNIVERSITY - यूनिवर्सिटी\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f06ed7e4-97bb-4780-cb2f-1327226a7e64"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARSHURAM tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "30270e8a-733a-432e-8992-34330ca44e04"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "परशुराम tensor([[43],\n",
            "        [49],\n",
            "        [55],\n",
            "        [66],\n",
            "        [49],\n",
            "        [63],\n",
            "        [47],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cra9toTiOoPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zaJq2pOrM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "8f63335b-fa7d-401f-d4db-872dc20c508d"
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "b6fb8423-1f01-4f3c-f1b9-f5dd9a8fb752"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ॒\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) भ\n",
            "torch.Size([1, 129]) ़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) ष\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) ़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) य़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) ़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) ष\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) ़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) य़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n",
            "torch.Size([1, 129]) ़\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) ष\n",
            "torch.Size([1, 129]) फ\n",
            "torch.Size([1, 129]) व\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "30e5ee26-fe66-426b-e2b6-5385c6c723f4"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "55e23d81-96e5-456d-eb0b-eb470bfd3531"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n",
            "torch.Size([1, 129]) ँ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9",
        "colab_type": "text"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8",
        "colab_type": "text"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "colab_type": "code",
        "outputId": "9b3f7f5a-b98b-4203-d137-1780ee362fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.182112455368042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.51503497, 0.50318944, ..., 0.1821585 , 0.18211246,\n",
              "       0.18207802])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab_type": "code",
        "outputId": "6e8ed733-4b95-4eae-ac09-be4f6a905d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.1429685652256012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn7EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoderAttention_Type2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "183c661a-56c9-4f31-a894-188207c58104"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  63.53564962814963\n",
            "Acurracy with attention 69.0169871794872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukoNAs8wP-GH",
        "colab_type": "text"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Train longer and check accuracy - play with different hyperparameters\n",
        "2. Visualise attention - which part of the encoder output are we attending to\n",
        "3. Improve performance with batching - use the packing idea from earlier\n",
        "4. Try other attention mechanisms\n"
      ]
    }
  ]
}